{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogBw1yN2Uc51",
        "outputId": "25d9b443-e960-44a7-dd5e-601b0361193b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install efficientnet_pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYXndfUqrOvQ",
        "outputId": "cca87b48-3fb7-4a38-8363-074cb7fcd1cb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting efficientnet_pytorch\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet_pytorch) (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (4.12.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->efficientnet_pytorch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->efficientnet_pytorch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->efficientnet_pytorch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->efficientnet_pytorch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->efficientnet_pytorch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->efficientnet_pytorch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->efficientnet_pytorch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->efficientnet_pytorch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->efficientnet_pytorch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->efficientnet_pytorch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->efficientnet_pytorch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->efficientnet_pytorch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet_pytorch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet_pytorch) (1.3.0)\n",
            "Building wheels for collected packages: efficientnet_pytorch\n",
            "  Building wheel for efficientnet_pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet_pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16429 sha256=49232218b8e7a9db153e140009613157d9e9604d44bde8d853bdc122d446c196\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n",
            "Successfully built efficientnet_pytorch\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, efficientnet_pytorch\n",
            "Successfully installed efficientnet_pytorch-0.7.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 로드\n",
        "import time\n",
        "import datetime\n",
        "import os\n",
        "import copy\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.optim import lr_scheduler\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "from tqdm import tqdm\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "WPTDM3Ltm1fz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "b_wkbw4Bmpfg"
      },
      "outputs": [],
      "source": [
        "#transforms.Compose : Rescale 과 RandomCrop 을 한번에 수행\n",
        "#Rescale: 이미지의 크기를 조절\n",
        "#RandomCrop: 이미지를 무작위로 자른다\n",
        "#정규화\n",
        "def func(x):  #아래 transforms_train = 코드에서 transforms.Lambda(lambda x: x.rotate(90)) 에서 나는 에러를 잡기 위해 def로 빼주고 람다 속 람다를 제거함\n",
        "    return x.rotate(90)\n",
        "transforms_train = transforms.Compose([\n",
        "    transforms.Resize([int(600), int(600)], interpolation=transforms.InterpolationMode.BOX), # interpolation=4 워닝을 제거하기 위해 변형\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.Lambda(func),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomAffine(0, shear=10, scale=(0.8, 1.2)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "transforms_val = transforms.Compose([\n",
        "    transforms.Resize([int(600), int(600)], interpolation=transforms.InterpolationMode.BOX),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "#data_train_path 경로의 이미지를 transforms.Compose 로 정규화한 데이터 기준으로 트랜스폼\n",
        "# train_data_set = datasets.ImageFolder(data_train_path, transform=transforms_train)\n",
        "# val_data_set = datasets.ImageFolder(data_validation_path, transform=transforms_val)\n",
        "# # 변수 선언\n",
        "# dataloaders, batch_num = {}, {}\n",
        "# # dataloaders 빈딕셔너리에 train/val 키랑 DataLoder 밸류 넣기\n",
        "# # DataLoader로 학습용 데이터 준비 : 데이터셋의 특징(feature)을 가져오고 하나의 샘플에 정답(label)을 지정하는 일을 한다\n",
        "# dataloaders['train'] = DataLoader(train_data_set,\n",
        "#                                   batch_size=hyper_param_batch,\n",
        "#                                   shuffle=True,\n",
        "#                                   num_workers=0)  # aihub코드  num_workers = 4\n",
        "# dataloaders['val'] = DataLoader(val_data_set,\n",
        "#                                 batch_size=hyper_param_batch,\n",
        "#                                 shuffle=False,\n",
        "#                                 num_workers=0)  # aihub코드  num_workers = 4\n",
        "#즉 dataloaders 딕셔너리에는 train / val 이 key 각 밸류는 정규화한 이미지 데이터에 + 라벨이 붙음\n",
        "#DataLoader를 통해 네트워크에 올리기\n",
        "#from torch.utils.data import Dataset,DataLoader\n",
        "#testloader = DataLoader(testset, batch_size=2, shuffle=False, num_workers=0)\n",
        "    #데이터 로더는 데이터의 대량 가져오기 또는 내보내기를 위한 클라이언트 응용 프로그램\n",
        "    #for data, target in testloader: 에서 data는 데이터의 특징  target은 데이터의 정답값"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PATH = '/content/drive/MyDrive/project/scalp_weights/'+'aram_model5.pt'   # 모델경로\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")     # 쿠다 쓸 수 있으면 사용\n",
        "# model = torch.load(PATH, map_location=device)     # 모델로드\n",
        "# with torch.no_grad(): # 평가할 땐  gradient를 backpropagation 하지 않기 때문에 no grad로 gradient 계산을 막아서 연산 속도를 높인다\n",
        "#             for data, target in tqdm(testloader):\n",
        "#                 data, target  = data.to(device), target.to(device)\n",
        "#                 output = model(data)   # model1에 데이터를 넣어서 아웃풋 > [a,b,c,d] 각 0,1,2,3 의 확률값 리턴 가장 큰 것이 pred\n",
        "#                 # output_list.append(output);\n",
        "#                 test_loss += F.nll_loss(output, target, reduction = 'sum').item()  # test_loss변수에 각 로스를 축적\n",
        "#                 pred = output.argmax(dim=1, keepdim=True) # argmax : 리스트에서 최댓값의 인덱스를 뽑아줌 > y값아웃풋인덱\n",
        "#                 correct += pred.eq(target.view_as(pred)).sum().item() # accuracy 측정을 위한 변수 # 각 예측이 맞았는지 틀렸는지 correct변수에 축적 맞을 때마다 +1  # # view_as() 함수는 target 텐서를 view_as() 함수 안에 들어가는 인수(pred)의 모양대로 다시 정렬한다. #  view_as() 함수는 target 텐서를 view_as() 함수 안에 들어가는 인수(pred)의 모양대로 다시 정렬한다. #  pred.eq(data) : pred와 data가 일치하는지 검사\n",
        "# test_loss /= len(testloader.dataset)  # 로스축적된 로스를 데이터 수(경로안jpg수)로 나누기\n",
        "# # 로스, 아큐러시 출력 ( :.4f 소수점반올림 )\n",
        "# print('\\nTest set: Average Loss: {:.4f}, Accuracy: {}/{} ({:.4f}%)\\n'.format(test_loss, correct, len(testloader.dataset), 100. * correct / len(testloader.dataset)))  # 축적된 예측값을 데이터 개수로 나누기 *100  확률%값"
      ],
      "metadata": {
        "id": "zqxpqOVOmufD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'efficientnet-b6'\n",
        "num_classes = 4  # 여기선 고정값 아웃풋 0 1 2 3 // 4가지"
      ],
      "metadata": {
        "id": "9VE1eBm4sBMj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#웹페이지에서 이미지를 업로드 받은 후 연산시간을 줄이기 위해 미리 로드\n",
        "#PATH\n",
        "#checkpoint_model2.pt\n",
        "PATH2 = '/content/drive/MyDrive/capstone/scalp_weights/'+'checkpoint_model2.pt'  # 모델2 피지과다\n",
        "PATH3 = '/content/drive/MyDrive/capstone/scalp_weights/'+'checkpoint_model3.pt'  # 모델3 모낭사이홍반\n",
        "PATH6 = '/content/drive/MyDrive/capstone/scalp_weights/'+'checkpoint_model6.pt'  # 모델6 탈모\n",
        "\n",
        "#cuda\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#모델 로드\n",
        "\n",
        "model2 = EfficientNet.from_pretrained(model_name, num_classes=num_classes).to(device)  # 모델 다운로드\n",
        "model3 = EfficientNet.from_pretrained(model_name, num_classes=num_classes).to(device)\n",
        "model6 = EfficientNet.from_pretrained(model_name, num_classes=num_classes).to(device)\n",
        "\n",
        "# 저장된 state_dict 로드\n",
        "\n",
        "checkpoint2 = torch.load(PATH2)\n",
        "checkpoint3 = torch.load(PATH3)\n",
        "checkpoint6 = torch.load(PATH6)\n",
        "\n",
        "# state_dict를 각각의 모델에 로드\n",
        "model2.load_state_dict(checkpoint2['model_state_dict'])\n",
        "model3.load_state_dict(checkpoint3['model_state_dict'])\n",
        "model6.load_state_dict(checkpoint6['model_state_dict'])\n",
        "\n",
        "#모델을 평가모드로 전환   # 평가모드와 학습모드의 layer 구성이 다르다\n",
        "model2.eval()\n",
        "model3.eval()\n",
        "model6.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfzWEh6unELb",
        "outputId": "916185e6-ce03-446e-ff57-cd6ef9d947e3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained weights for efficientnet-b6\n",
            "Loaded pretrained weights for efficientnet-b6\n",
            "Loaded pretrained weights for efficientnet-b6\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EfficientNet(\n",
              "  (_conv_stem): Conv2dStaticSamePadding(\n",
              "    3, 56, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
              "    (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
              "  )\n",
              "  (_bn0): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "  (_blocks): ModuleList(\n",
              "    (0): MBConvBlock(\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        56, 56, kernel_size=(3, 3), stride=[1, 1], groups=56, bias=False\n",
              "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        56, 14, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        14, 56, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        56, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (1-2): 2 x MBConvBlock(\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        32, 32, kernel_size=(3, 3), stride=(1, 1), groups=32, bias=False\n",
              "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (3): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        192, 192, kernel_size=(3, 3), stride=[2, 2], groups=192, bias=False\n",
              "        (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        192, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (4-8): 5 x MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        240, 240, kernel_size=(3, 3), stride=(1, 1), groups=240, bias=False\n",
              "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (9): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        240, 240, kernel_size=(5, 5), stride=[2, 2], groups=240, bias=False\n",
              "        (static_padding): ZeroPad2d((1, 2, 1, 2))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        240, 72, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(72, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (10-14): 5 x MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        72, 432, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(432, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        432, 432, kernel_size=(5, 5), stride=(1, 1), groups=432, bias=False\n",
              "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(432, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        432, 18, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        18, 432, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        432, 72, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(72, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (15): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        72, 432, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(432, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        432, 432, kernel_size=(3, 3), stride=[2, 2], groups=432, bias=False\n",
              "        (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(432, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        432, 18, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        18, 432, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        432, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (16-22): 7 x MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        144, 864, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(864, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        864, 864, kernel_size=(3, 3), stride=(1, 1), groups=864, bias=False\n",
              "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(864, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        864, 36, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        36, 864, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        864, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (23): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        144, 864, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(864, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        864, 864, kernel_size=(5, 5), stride=[1, 1], groups=864, bias=False\n",
              "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(864, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        864, 36, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        36, 864, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        864, 200, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(200, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (24-30): 7 x MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        200, 1200, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1200, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1200, 1200, kernel_size=(5, 5), stride=(1, 1), groups=1200, bias=False\n",
              "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1200, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1200, 50, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        50, 1200, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1200, 200, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(200, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (31): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        200, 1200, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1200, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1200, 1200, kernel_size=(5, 5), stride=[2, 2], groups=1200, bias=False\n",
              "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1200, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1200, 50, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        50, 1200, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1200, 344, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (32-41): 10 x MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        344, 2064, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(2064, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        2064, 2064, kernel_size=(5, 5), stride=(1, 1), groups=2064, bias=False\n",
              "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(2064, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        2064, 86, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        86, 2064, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        2064, 344, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (42): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        344, 2064, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(2064, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        2064, 2064, kernel_size=(3, 3), stride=[1, 1], groups=2064, bias=False\n",
              "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(2064, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        2064, 86, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        86, 2064, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        2064, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (43-44): 2 x MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        576, 3456, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(3456, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        3456, 3456, kernel_size=(3, 3), stride=(1, 1), groups=3456, bias=False\n",
              "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(3456, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        3456, 144, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        144, 3456, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        3456, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "  )\n",
              "  (_conv_head): Conv2dStaticSamePadding(\n",
              "    576, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "    (static_padding): Identity()\n",
              "  )\n",
              "  (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
              "  (_dropout): Dropout(p=0.5, inplace=False)\n",
              "  (_fc): Linear(in_features=2304, out_features=4, bias=True)\n",
              "  (_swish): MemoryEfficientSwish()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#전처리 : 트랜스폼 규칙 선언 # validation set 의 트랜스폼 규칙과 동일\n",
        "transforms_test = transforms.Compose([  transforms.Resize([int(600), int(600)], interpolation=transforms.InterpolationMode.BOX),\n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])    ])\n",
        "#root 경로 폴더 속 jpg를 전처리, 텐서화 # /content/drive/MyDrive/capstone/\n",
        "testset = torchvision.datasets.ImageFolder(root = '/content/drive/MyDrive/capstone/test_data',\n",
        "                    transform = transforms_test)\n",
        "#앞서 전처리한 testset 을 DataLoader를 통해 네트워크에 올리기\n",
        "testloader = DataLoader(testset, batch_size=2, shuffle=False, num_workers=0)\n",
        "    #데이터 로더는 데이터의 대량 가져오기 또는 내보내기를 위한 클라이언트 응용 프로그램"
      ],
      "metadata": {
        "id": "DnpXGrP9oSIa"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for data, target in testloader: 에서 data는 데이터의 특징  target은 데이터의 정답값\n",
        "with torch.no_grad(): # 평가할 땐  gradient를 backpropagation 하지 않기 때문에 no grad로 gradient 계산을 막아서 연산 속도를 높인다\n",
        "  for data, target in testloader:\n",
        "    data, target  = data.to(device), target.to(device)\n",
        "    output2 = model2(data) # model에 데이터를 넣어서 아웃풋 > [a,b,c,d] 각 0,1,2,3 의 확률값 리턴 가장 큰 것이 pred\n",
        "    output3 = model3(data)\n",
        "    output6 = model6(data)\n",
        "    #predict # # 0~3값만 뽑기\n",
        "    m2p = output2.argmax(dim=1, keepdim=True)[0][0].tolist()\n",
        "    m3p = output3.argmax(dim=1, keepdim=True)[0][0].tolist()\n",
        "    m6p = output6.argmax(dim=1, keepdim=True)[0][0].tolist()\n",
        "\n",
        "    print(f\"Model2 prediction: {m2p}, Model3 prediction: {m3p}, Model6 prediction: {m6p}\")"
      ],
      "metadata": {
        "id": "hlCuv02Qn9JB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d145d60d-44f3-44db-d943-e4c97a8a18ac"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model2 prediction: 0, Model3 prediction: 0, Model6 prediction: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#진단\n",
        "d_list = [] # 두피유형진단결과\n",
        "    # # 두피 유형 진단법\n",
        "    # if m1p == 0 and m2p == 0 and m3p == 0 and m4p == 0 and m5p == 0 and m6p == 0 :\n",
        "    #     d1 = '정상입니다.'\n",
        "    #     d_list.append(d1)\n",
        "    # elif m1p != 0 and m2p == 0 and m3p == 0 and m4p == 0 and m5p == 0 and m6p == 0 :\n",
        "    #     d2 = '건성 두피입니다.'\n",
        "    #     d_list.append(d2)\n",
        "    # elif m1p == 0 and m2p != 0 and m3p == 0 and m4p == 0 and m5p == 0 and m6p == 0 :\n",
        "    #     d3 = '지성 두피입니다.'\n",
        "    #     d_list.append(d3)\n",
        "    # elif m2p == 0 and m3p != 0 and m4p == 0 and m5p == 0 and m6p == 0 :\n",
        "    #     d4 = '민감성 두피입니다.'\n",
        "    #     d_list.append(d4)\n",
        "    # elif m2p != 0 and m3p != 0 and m4p == 0 and m6p == 0 :\n",
        "    #     d5 = '지루성 두피입니다.'\n",
        "    #     d_list.append(d5)\n",
        "    # elif m3p == 0 and m4p != 0 and m6p == 0 :\n",
        "    #     d6 = '염증성 두피입니다.'\n",
        "    #     d_list.append(d6)\n",
        "    # elif m3p == 0 and m4p == 0 and m5p != 0 and m6p == 0 :\n",
        "    #     d7 = '비듬성 두피입니다.'\n",
        "    #     d_list.append(d7)\n",
        "    # elif m1p == 0 and m2p != 0 and m3p == 0 and m4p == 0 and m5p == 0 and m6p != 0 :\n",
        "    #     d8 = '탈모입니다.'\n",
        "    #     d_list.append(d8)\n",
        "    # else:\n",
        "    #     d9 = '복합성 두피입니다.'\n",
        "    #     d_list.append(d9)\n",
        "\n",
        "# 두피 유형 진단법\n",
        "if m2p == 0 and m3p == 0 and m6p == 0:\n",
        "    d1 = '정상입니다.'\n",
        "    d_list.append(d1)\n",
        "elif m2p != 0 and m3p == 0 and m6p == 0:\n",
        "    d2 = '지성 두피입니다.'\n",
        "    d_list.append(d2)\n",
        "elif m2p == 0 and m3p != 0 and m6p == 0:\n",
        "    d3 = '민감성 두피입니다.'\n",
        "    d_list.append(d3)\n",
        "elif m2p != 0 and m3p != 0 and m6p == 0:\n",
        "    d4 = '지루성 두피입니다.'\n",
        "    d_list.append(d4)\n",
        "elif m2p != 0 and m3p == 0 and m6p != 0:\n",
        "    d5 = '탈모입니다.'\n",
        "    d_list.append(d5)\n",
        "else:\n",
        "    d6 = '복합성 두피입니다.'\n",
        "    d_list.append(d6)\n",
        "\n",
        "# 진단 결과 출력\n",
        "print(d_list)"
      ],
      "metadata": {
        "id": "aDhuVlUMtwtO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58098abd-4eab-48c4-ad17-3612f9330150"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['복합성 두피입니다.']\n"
          ]
        }
      ]
    }
  ]
}